##  ########################################



**AI Performance = Data(70%) + Model(CNN、RNN、Transformer、Bert、GPT 20%) + Trick(loss、optimizer、etc 10%)** 



####  调参经验

```
网络：
 1.Backbone和Heads的不同学习率: 因为Backbone和Heads在结构上的差异，使用不同的学习率是可以有效的使得网络达到更好, 更稳定的收敛效果


数据：
 1.数据归一化: 由于白噪声的存在，医学图像、遥感图像则不能简单的归一化到0-1，普通数码照片可以简单的将0-255线性映射到0-1进行归一化
 2.cv2读取图片速度快比Pillow快
 3.Callback: 自己给自己的测试集打Label放进训练


train.py
 01. DropOut2d / DropPath / DropBlock (block size控制大小最好在7x7，keep prob在整个训练过程中从1逐渐衰减到指定阈值)
 02. Batch Normalization / Group Normalization (每组channel为16)
 03. Focal Loss: 对CE loss增加了一个调制系数来降低容易样本的权重值，使得训练过程更加关注困难样本
 04. 多loss加权混合: 保证组合后的损失函数下降不平衡导致的损失函数的倾斜化
 05. OneCycleLR + SGD / Adam （torch.optim.lr_scheduler.ReduceLROnPlateau）
 06. L1 L2正则化 == weight decany
 07. 混合精度FP16: 加快训练速度，提高训练精度
 08. 加速训练pin_memory=true work_numbers=x (卡的数量x4)，data.to(device, no_blocking=True)设置为True后数据直接保存在锁页内存中，后续直接传入cuda，否则需要先从虚拟内存中传入锁页内存中再传入cuda
 09. Warm Up / Early stopping
 10. TTA: 对于测试数据集进行不同方向的预测后将预测的模型进行组合，在不改变模型内部参数的情况下，对效果进行提升 (增加推理时间)
 11. seed（42）随即种子数设置为42
 12. 3x3卷积有利于保持图像性质
 13. ReLU可使用inplace操作减少显存消耗
 14. Label Smoothing: 使得原本的hard-target变为soft-target，让标签分布的熵增大,使网络优化更加平滑,通常用于减少训练的过拟合问题并进一步提高分类性能
 15. With Flooding: 当training loss大于一个阈值时，进行正常的梯度下降；当training loss低于阈值时，会反过来进行梯度上升，让training loss保持在一个阈值附近，让模型持续进行"random walk"
 16.权重初始化时可使用He初始化, 但是更为重要的是对应权重正负号, 值没有那么重要
```



**在训练过程中，loss并不是一直在下降，准确率一直在提升的，会有一些震荡存在，只要总体趋势是在收敛就行；**

```
train loss 不断下降，test loss不断下降，说明网络仍在学习;

train loss 不断下降，test loss趋于不变，说明网络过拟合;

train loss 趋于不变，test loss不断下降，说明数据集100%有问题;

train loss 趋于不变，test loss趋于不变，说明学习遇到瓶颈，需要减小学习率或批量数目;
```



#### 深度学习挑战

- **应该更多地关注边缘情况（也就是异常值，或不寻常的情况），并思考这些异常值对预测可能意味着什么：**我们手上有大量的关于日常事务的数据，当前的技术很容易处理这些数据；而对于罕见的事件，我们得到的数据非常少，且目前的技术很难去处理这些数据；
- **我们人类拥有大量的不完全信息推理的技巧，也许可以克服生活中的长尾问题：**但对于目前流行的、更多依赖大数据而非推理的人工智能技术来说，长尾问题是一个非常严重的问题；
- 世上并不只有一种思维方式，因为思维并不是一个整体。相反，**思维是可以分为部分的，而且其不同部分以不同的方式运作：**例如，深度学习在识别物体方面做得相当不错，但在计划、阅读或语言理解方面做得差一些；
- **使用深度学习进行调试非常困难，因为没有人真正理解它是如何工作的，也没有人知道如何修复问题：**大众所知道的那种调试在经典编程环境中并不适用；



## ########################################



## 深度学习



------

#### 局部最小值 & 鞍点（Hessian矩阵）

- 求导，得到导数为0的点，并进行泰勒展开；
- 泰勒展开含二阶导数部分，求其Hessian矩阵及其对应特征值；
- 特征值全部大于0，则为局部最小值；特征值全部小于0，则为局部最大值；特征值有正有负，则为鞍点；

<img src="%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.assets/image-20220826223004304.png" alt="image-20220826223004304" style="zoom: 50%;" />

<img src="%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.assets/image-20220826223246364.png" alt="image-20220826223246364" style="zoom:50%;" />



```
**如果正定Hessian矩阵的特征值都差不多，那么梯度下降的收敛速度越快，反之如果其特征值相差很大，那么收敛速度越慢；**
```



一阶梯度下降方法中$\alpha$控制步长：
$$
x_{t+1}=x_{t}-\alpha g, \quad g=f^{\prime}\left(x_{t}\right)                 
$$
二阶方法将函数$f(\theta)$在局部极值点附$f(\theta^*)$近进行二阶Taylor展开，其中$g$为梯度向量，$H$为Hessian矩阵：
$$
f\left(\theta^{*}+\Delta \theta\right) \approx f\left(\theta^{*}\right)+g^{T} \Delta \theta+\frac{1}{2}(\Delta \theta)^{T} H(\Delta \theta)
$$
对上式求导并令其为0，以求在二阶近似原函数的情况下快速求出函数极值点：
$$
\Delta \theta=-H^{-1} g
\Rightarrow x_{t+1}=x_{t}-H^{-1} g, g=f^{\prime}\left(x_{t}\right)
$$
结合两个更新公式可知**Hessian矩阵的特征值控制了更新步长：**$\alpha = H^{-1}$

详细的，对实对称矩阵而言：$H=E \Lambda E^{T}$，其中$E=\left[e_{1} e_{2} \ldots e_{n}\right]$是单位特征向量矩阵，$\Lambda=\operatorname{diag}\left(\left[\lambda_{1} \lambda_{2} \ldots \lambda_{n}\right]\right)$是对应特征值对角矩阵，则：
$$
H^{-1} g=\left(E \Lambda E^{T}\right)^{-1} g=E \Lambda^{-1} E^{T} g=\sum_{i}^{n} \frac{e_{i}^{T} g}{\lambda_{i}} e_{i}
$$
可以看出，这**里控制步长的有对应的Hessian矩阵特征值**，极端的![[公式]](https://www.zhihu.com/equation?tex=%5Calpha+g)则表示![[公式]](https://www.zhihu.com/equation?tex=%5Calpha+%5CLeftrightarrow++1%2F%5Clambda_%7Bi%7D%2C+%5Cvee+i)这种，**若特征值间差异巨大，则有些方向学习缓慢，有些不断波动**（二维情况就是经常看到的那种蛇形曲线...)，这些现象也侧面说明了步长这东西；



------

#### Small Batch & Large Batch

![image-20220826224718603](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.assets/image-20220826224718603.png)

![image-20220826225430187](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.assets/image-20220826225430187.png)



------

#### 梯度下降 & 学习率



**一阶方法：**随机梯度下降（SGD）、动量（Momentum）、牛顿动量法（Nesterov动量）、AdaGrad（自适应梯度）、RMSProp（均方差传播）、Adam、Nadam

**二阶方法：**牛顿法、拟牛顿法、共轭梯度法（CG）、BFGS、L-BFGS

**自适应优化：**Adagrad（累积梯度平方）、RMSProp（累积梯度平方的滑动平均）、Adam（带动量的RMSProp，即同时使用梯度的一、二阶矩）

 

------



**一个框架来梳理所有的优化算法：**

- 首先定义待优化参数 $w$,   目标函数$f(w)$,   初始学习率 $\alpha_{\circ}$
- 之后开始进行迭代优化，在每个epoch $\boldsymbol{t}$ :
  - 计算目标函数关于当前参数的梯度： $g_{t}=\nabla f\left(w_{t}\right)$
  - 根据历史梯度计算一阶动量和二阶动量:
    $m_{t}=\phi\left(g_{1}, g_{2}, \cdots, g_{t}\right) ; V_{t}=\psi\left(g_{1}, g_{2}, \cdots, g_{t}\right)$
  - 计算当前时刻的下降梯度： $\eta_{t}=\alpha \cdot m_{t} / \sqrt{V_{t}}$
  - 根据下降梯度进行更新： $w_{t+1}=w_{t}-\eta_{t}$

------



**马鞍状的最优化地形，其中对于不同维度它的曲率不同（一个维度下降另一个维度上升）**

- **基于动量**的方法使得最优化过程看起来像是一个球滚下山的样子
- **SGD**很难突破对称性，一直卡在顶部
- **RMSProp之类**的方法能够看到马鞍方向有很低的梯度（因为在RMSProp更新方法中的分母项，算法提高了在该方向的有效学习率，使得RMSProp能够继续前进）

------



**SGD（普通更新）**



最简单的沿着负梯度方向改变参数；假设有一个**参数向量x**及其**梯度dx**，那么最简单的更新的形式是：

```python
# 普通更新
x += - learning_rate * dx
```



- SGD最大的缺点是下降速度慢，而且可能会在沟壑的两边持续震荡，停留在一个局部最优点； 
- $(\mathrm{W}, \mathrm{b})$ 的每一个分量获得的梯度绝对值有大有小,，一些情况下，将会迫使优化路径变成Z字形状；
- SGD求梯度的策略过于随机，由于上一次和下一次用的是完全不同的Batch数据,，将会出现优化的方向随机的情况；



------

**SGDM（动量更新，解决梯度随机性）**



该方法从**物理角度**上对于最优化问题得到的启发：

从本质上说，动量法就像我们从山上推下一个球，球在滚下来的过程中累积动量，变得越来越快（直到达到终极速度，如果有空气阻力的存在，则$\mu$<1）；同样的事情也发生在参数的更新过程中：**对于在梯度点处具有相同的方向的维度，其动量项增大，对于在梯度点处改变方向的维度，其动量项减小。**因此我们可以得到更快的收敛速度，同时可以减少摇摆。



**也就是说，t 时刻的下降方向，不仅由当前点的梯度方向决定，而且由此前累积的下降方向决定。 mu的经验值为0.9，这就意味着下降方向主要是此前累积的下降方向，并略微偏向当前时刻的下降方向**；



在SGD中，梯度影响**位置**；

而在SGDM的更新中，物理观点建议**梯度只是影响速度**，然后**速度再影响位置**： 

```python
 # 动量更新
    v = mu * v - (1 - mu) * dx # 与速度融合，mu其物理意义与摩擦系数更一致
    x += v # 与位置融合
    
# mu通常取值为0.9，这就意味着下降方向主要是此前累积的下降方向，并略微偏向当前时刻的下降方向
```

![image-20220826230230491](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.assets/image-20220826230230491.png)

![image-20220826230752974](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.assets/image-20220826230752974.png)



------



**NAG（Nesterov动量）**



SGD 还有一个问题是困在局部最优的沟壑里面震荡。想象一下你走到一个盆地，四周都是略高的小山，你觉得没有下坡的方向，那就只能待在这里了。可是如果你爬上高地，就会发现外面的世界还很广阔。因此我们不能停留在当前位置去观察未来的方向，而要向前一步、多看一步、看远一些。



当参数向量位于某个位置 *x* 时，观察上面的动量更新公式，动量部分会通过$mu * v$改变参数向量；

因此，如要计算梯度，那么可以将**未来的近似位置**$ x+mu*v$ 看做是“**向前看**”，这个点在我们一会儿要停止的位置附近。因此，**计算** $ x+mu*v$**的梯度**而不是“旧”位置 *x* 的梯度，使用Nesterov动量，我们就在这个“向前看”的地方计算梯度

```python
x_ahead = x + mu * v
计算dx_ahead(在x_ahead处的梯度，而不是在x处的梯度)
v = mu * v - learning_rate * dx_ahead
x += v  
```

上面的程序还得计算dx_ahead，通过对 x_ahead = x + mu * v 使用变量变换进行改写，然后用x_ahead而不是x来表示上面的更新，即：实际**存储**的参数向量总是**向前一步版本**。x_ahead 的公式（将其**重新命名为x**）就变成了：

```python
v_prev = v # 存储备份
v = mu * v - learning_rate * dx # 速度更新保持不变，mu=0.9
x += -mu * v_prev + (1 + mu) * v # 位置更新变了形式
```



------



**Adagrad**

![image-20220827213002839](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.assets/image-20220827213002839.png)



------



**RMSprop**



引用自Geoff Hinton的Coursera课程，具体说来，就是它使用了一个**梯度平方的滑动平均**：

```python
cache = decay_rate * cache + (1 - decay_rate) * dx**2
x += - learning_rate * dx / (np.sqrt(cache) + eps)
```

decay_rate=0.9，learning_rate=0.001，RMSProp仍然是基于梯度的大小来对每个权重的学习率进行修改，但**其更新不会让学习率单调变小**； 

- 不累积全部历史梯度，而**只关注过去一段时间窗口的下降梯度**，而指数移动平均值大约就是过去一段时间的平均值，因此我们用这一方法来计算二阶累积动量：
- 历史中梯度权重不同，最近一些梯度具有较大的影响；

![image-20220827213814881](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.assets/image-20220827213814881.png)



------



**Adam**



**Adam本质上实际是RMSProp+动量**：Adam对每一个参数都计算自适应的学习率：除了像RMSprop一样存储一个历史梯度平方的滑动平均$vt$，Adam同时还保存一个历史梯度的滑动平均$m_t$，类似于动量：

```python
# 根据历史梯度计算一阶动量和二阶动量
m_t = beta1*m + (1-beta1)*dx
v_t = beta2*v + (1-beta2)*(dx**2)

# 当mt和vt初始化为0向量时，发现它们都偏向于0，尤其是在初始化的步骤和当衰减率很小的时候（例如beta1和beta2趋向于1）,通过计算偏差校正的一阶矩和二阶矩估计来抵消偏差
m_hat = m_t / 1 - (beta1 ** t）
v_hat = v_t / 1 - (beta2 ** t)

x += - learning_rate * m_hat / (np.sqrt(v_hat) + eps)  # eps=1e-8, beta1=0.9, beta2=0.999
```

![image-20220827214144011](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.assets/image-20220827214144011.png)



------



**学习率 Learning Rate**

![image-20220827214838018](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.assets/image-20220827214838018.png)



**Warm Up 需要在训练最初使用较小的学习率来启动，并很快切换到大学习率而后进行常见的 Decay：**$\sigma$表示历史统计数据，而在训练开始时这一数据并不准确，所以给它一个较小的学习率(0.001)让它在原地学习，之后数据会逐渐准确，可以将其增加(0.1)，之后使用常见的Learning Rate Decay；

![image-20220827215343432](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.assets/image-20220827215343432.png)



------

#### Batch Normalization & Dropout



**解决Internal Covariate Shift**：在深层网络训练的过程中，由于网络中参数变化而引起内部结点数据分布发生变化的这一过程；之所以训练收敛慢，一般是整体分布逐渐往非线性函数的取值区间的上下限两端靠近，所以这**导致反向传播时低层神经网络的梯度消失**，这是训练深层神经网络收敛越来越慢的**本质原因**，**而BN就是通过一定的规范化手段，把每层神经网络任意神经元这个输入值的分布强行拉回到均值为0方差为1的分布；**



**优点：**

- **BN使得网络中每层输入数据的分布相对稳定，加速模型学习速度；**
- **BN允许网络使用饱和性激活函数（例如sigmoid，tanh等），缓解梯度消失问题；**
- **起到一定的正则化作用，防止过拟合；**
- **BN使得模型对网络中的参数不那么敏感，简化调参过程，使得网络学习更加稳定；**



------



$Input: B=\left\{x_{1 \ldots m}\right\} ; \gamma, \beta($ parameters to be learned $)$

$\text { Output }:\left\{y_{i}=B N_{\gamma, \beta}\left(x_{i}\right)\right\} \\$
$$
\begin{array}{r}

\mu_{B} \leftarrow \frac{1}{m} \sum_{i=1}^{m} x_{i} \\
\sigma_{B}^{2} \leftarrow \frac{1}{m} \sum_{i=1}^{m}\left(x_{i}-\mu_{B}\right)^{2} \\
\tilde{x}_{i} \leftarrow \frac{x_{i}-\mu_{B}}{\sqrt{\sigma_{B}^{2}+\epsilon}} \\
y_{i} \leftarrow \gamma \tilde{x}_{i}+\beta
\end{array}
$$

- **BN [B, H, W] 的精髓在于归一之后，使用$\gamma, \beta$作为还原参数，让数据尽可能保留原始的表达能力；**

```
批规范化（Batch Normalization，BN）：在 minibatch维度 上在每次训练iteration时对隐藏层进行归一化
标准化（Standardization）：对输入 数据 进行归一化
正则化（Regularization）：通常是指对 参数 在量级和尺度上做约束，缓和过拟合情况，L1 L2正则化
```



均值的计算，就是在一个批次内将每个通道中的数字单独加起来，再除以 $N*W*H$；举个例子：该批次内有10张图片，每张图片有三个通道RBG，每张图片的高、宽是H、W，那么均值就是计算**10张图片R通道的像素数值总和**除以$10*W*H$，再计算B通道全部像素值总和除以$N*W*H$，最后计算G通道的像素值总和除以$N*W*H$。方差的计算类似；

可训练参数 $\beta,\gamma$的维度等于**张量的通道数**，在上述例子中，RBG三个通道分别需要一个 $\beta和一个\gamma$，所以$\vec{\gamma}, \vec{\beta}$的维度等于3；



------

**基本理论**

![image-20220828125737750](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.assets/image-20220828125737750.png)

在未进行Normalization前所有的数据都相互独立，但是经过Normalization会使得各个数据间相互关联，每一个数据的改变会改变$\mu和\sigma$进而改变后一层数据；

![image-20220828130410672](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.assets/image-20220828130410672.png)

$\beta和\gamma$为可学习参，用于还原原始参数分布；

![image-20220828130924049](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.assets/image-20220828130924049.png)

![image-20220828131321546](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.assets/image-20220828131321546.png)

![image-20220828133459231](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.assets/image-20220828133459231.png)

------

**PyTorch中BN**



在PyTorch中**将gamma和beta改叫weight、bias**，使得打印网络参数时候只会打印出weight和bias（PyTorch中只有可学习的参数才称为Parameter）,但是`Net.state_dict()`是有running_mean和running_var的，**因为running_mean和running_var不是可以学习的变量，只是训练过程对很多batch的数据统计;**



BN层的**输出Y与输入X之间的关系**：**Y = (X - running_mean) / sqrt(running_var + eps) * gamma + beta**，其中**gamma、beta为可学习参数（在PyTorch中分别改叫weight和bias），训练时通过反向传播更新**；而**running_mean、running_var则是在前向时先由X计算出mean和var，再由mean和var以动量momentum来更新running_mean和running_var**，所以**在训练阶段，running_mean和running_var在每次前向时更新一次**；在**测试阶段，则通过`net.eval()`固定该BN层的running_mean和running_var，此时这两个值即为训练阶段最后一次前向时确定的值，并在整个测试阶段保持不变；**



**先更新running_mean和running_var，再计算BN；**

```
训练时：
running_mean = (1 - momentum) * running_mean + momentum * mean_cur
running_var = (1 - momentum) * running_var + momentum * var_cur
```

```
测试时：
running_mean = running_mean
running_var = running_var
```



------

**Conv和BN的融合**
$$
\begin{aligned}
y_{\text {conv }} &=w \cdot x+b \\
y_{b n} &=\gamma \cdot\left(\frac{y_{\text {conv }}-E[x]}{\sqrt{\operatorname{Var}[x]+\epsilon}}\right)+\beta \\
&=\gamma \cdot\left(\frac{w x+b-E[x]}{\sqrt{\operatorname{Var}[x]+\epsilon}}\right)+\beta \\
\hat{w} &=\frac{\gamma}{\sqrt{\operatorname{Var}[x]+\epsilon}} \cdot w \\
\hat{b} &=\frac{\gamma}{\sqrt{\operatorname{Var}[x]+\epsilon}} \cdot(b-E[x])+\beta \\
y_{b n} &=\hat{w} \cdot x+\hat{b}
\end{aligned}
$$

------

**Dropout**



`torch.nn.Dropout2d(p=0.5, inplace=False)`：input shape: (N, C, H, W)， output shape: (N, C, H, W)



**Dropout在层与层之间加噪声，是一种正则**；**在全连接使用，CNN用BN；**

Dropout 是**在训练过程中以一定的概率的使神经元失活，控制模型复杂度，提高模型的泛化能力，减少过拟合**，而在测试时，应该用整个训练好的模型，因此不需要Dropout；



- **Dropout 在训练时采用**，是为了减少神经元对部分上层神经元的依赖，类似将多个不同网络结构的模型集成起来，减少过拟合的风险；而在测试时，应该用整个训练好的模型，因此**测试时不需要dropout**；

- **在测试时如果丢弃一些神经元，这会带来结果不稳定的问题：**给定一个测试数据，有时候输出a有时候输出b，结果不稳定，用户可能认为模型预测不准。那么**一种”补偿“的方案就是每个神经元的权重都乘以一个p，这样在“总体上”使得测试数据和训练数据是大致一样的**。比如一个神经元的输出是x，那么在训练的时候它有p的概率参与训练，(1-p)的概率丢弃，那么它输出的期望是`p*x+(1-p)*0=px`，因此测试的时候把这个神经元的权重乘以p可以得到同样的期望；



------

**BN和Dropdout同时使用**



**方差偏移现象**

Dropout 与 Batch Normalization之间冲突的关键是**网络状态切换过程中存在神经方差的不一致行为，这种方差不匹配可能导致数值不稳定；而随着网络越来越深，最终预测的数值偏差可能会累计，从而降低系统的性能；**



- 假设某层单个神经元在某一Batch的Batch Normalization后输出的期望，方差分别为：$E\left(x_{i}\right)=e$,  $V\left(x_{i}\right)=v$；
- 对于Dropout，训练过程中的计算可以表示为：$x_{d}^{i}=\frac{x_{i}}{p} \delta_{i}$，其中$\delta_{i}$表示服从概率$p$伯努利分布采样的随机变量；
- 那么在训练阶段经过Dropout后，该Batch的期望和方差分别为：

$$
\begin{gathered}
E\left(x_{d}^{i}\right)=\frac{e}{p} * p+0 *(1-p)=e \\
V\left(x_{d}^{i}\right)=E\left((x_{d}^{i})^2\right)-E\left(x_{d}^{i}\right)^{2}=\frac{p *\left(V\left(x_{i}\right)+E\left(x_{i}\right)^{2}\right)}{p^{2}}-e^{2}=\frac{v+e^{2}}{p}-e^{2}
\end{gathered}
$$

​	 根据方差和期望的代数关系: $V(x)=E\left(x^{2}\right)-E(x)^{2}$ ：由于 $x_{d}^{i}=\frac{x^{i}}{p} * \delta_{i}$，即：
$$
E\left((x_{d}^{i})^2\right)=E\left(\left(\frac{x^{i}}{p} * \delta_{i}\right)^{2}\right)=\frac{E\left(\left(x^{i}\right)^{2}\right) * E\left(\delta_{i}^{2}\right)}{p^{2}}=\frac{\left(V\left(x^{i}\right)+E\left(x^{i}\right)^{2}\right) * p}{p^{2}}
$$

- 在Dropout测试阶段，$x_{d}^{i}=\delta_{i}$，不再根据采样概率$p$进行缩放，方差$V\left(x_{i}\right)=v$；
- 那么进行BN归一化时$x_{n o r m a l}^{i}=\frac{x^{i}-E_{\text {mean }}}{\sqrt{V_{\text {mean }}+\varepsilon}}$应该代入$v$，但是实际我们代入的是训练阶段的滑动平均值，即$\frac{v+e^{2}}{p}-e^{2}$，这就是BN和Dropout一同使用会使BN的测试阶段发生**方差偏移（Variance Shift）**的现象；



**解决方案**

- 不使用Dropout，即 $p=1$；
- **在所有 BN 层后使用 Dropout，因为Dropout是带来方差偏移的根本原因；**

- **把Dropout改为一种更加稳定的形式（对方差不敏感）：**高斯Dropout、均匀分布Dropout；



------

**BN / LN / IN / GN / CmBN**

![image-20220828151017742](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.assets/image-20220828151017742.png)



**对特征图做归一化，**对于`[B,C,W,H]`这样的训练数据而言：

- **BN** 是在`[B,W,H]`维度求均值方差进行规范化 -> CNN              
- **LN** 是对`[C,W,H]`维度求均值方差进行规范化   -> RNN，Transformer
- **IN** 是对`[W,H]`维度求均值方差进行规范化  -> 图像风格化：GAN，style transfer
- **GN **先对通道进行分组，每个组内的所有 [$C_i$,W,H] 维度求均值方差进行规范化  - > 目标检测，语义分割等要求尽可能大分辨率任务；

![image-20220828151458791](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.assets/image-20220828151458791.png)

- **CBN **将前k-1个iteration的样本参与当前均值和方差的计算；

![image-20220828150551417](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.assets/image-20220828150551417.png)



------

#### Transformer -> LayerNorm



- 相比于稳定前向输入分布，反向传播时mean和variance计算引入的梯度更有用，**LN可以稳定反向传播的梯度**；
- LN特别适合处理变长数据，因为是对channel维度（NLP中hidden维度）做操作，和句子长度和batch大小无关；

```python
CV: [B, C, Dim(H,W)]
NLP:[B, C, Dim]

CV或者NLP中都是在C维度Norm（C x Dim），但是不同数据的Dim不同，因此Norm看起来也似乎不同；
在CNN中Dim固定（H x W），因此图2中Dim[H, W]度画满了；而在Transformer中由于是变长数据，因此Dim不同，只画了一层，看起来像CV中的IN，但是他们的数据是不同的；
```

![image-20220914225541398](%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.assets/image-20220914225541398.png)

- **由于CV与NLP数据特性不同**（NLP数据在前向和反向传播中，batch统计量与梯度不稳定），因此Transformer使用LayerNorm，在ViT中使用BatchNorm要在FFN中间添加BN（**可以加速20% VIT的训练，原因是FFN没有被Normalized**）；



------

#### Data Augmentation

```
 - Mix up / Cutout / Mosaic
 - Label Smoothing
 - 物体的复制粘贴（小物体）
 - 随机剪裁，翻转，缩放，亮度，色调，饱和度
 - 对普通数码照片进行归一化可以简单的将0-255线性映射到0-1；而医学图像、遥感图像由于白噪声的存在则不能简单的归一化到0-1；
```

- 拼接增广指随机找几张图各取一部分或者缩小之后拼起来作为一幅图用，拼接出来的图有强烈的拼接痕迹；
- 抠洞指随机的将目标的一部分区域扣掉填充0值；

- **拼接、抠洞属于人为制造的伪显著区域，不符合实际情况，对工程应用来说没有意义，白白增加训练量；**
- **训练过程随机缩放也是没必要的，缩放之后的图像可能会导致特征图和输入图像映射错位；**



------

#### 数据类别不平衡

```
正负样本不均衡 + 类别不平衡（长尾分布）
```

**数据**

- **过采样** （增加噪声）/ **降采样**（先对样本聚类，在需要降采样的样本上，按类别进行降采样）
- Tomek连接 / **SMOTE**（选择少数样本，对其k临近插值）
- **增加数据** / **使用多种重采样的训练集**



- **评估指标：**避免使用Accuracy，可以用confusion matrix，precision，recall，f1-score，AUC，ROC等指标
- **Focal Loss**（正负样例不平衡alpha，简单困难样例不平衡belta）-> 目前普遍存在一个误解：认为focal loss是解决样本不均衡的杀器，实际上更重要的是**分类层bias的初始化**(yolox和v5都用了），另外在300Epochs训练后也可以解决不均衡问题



------



#### 梯度消失 & 梯度爆炸



目前优化神经网络的方法都是根据损失函数计算的误差通过梯度反向传播的方式，指导深度网络权值的更新优化。其中将误差从末层往前传递的过程需要**链式法则（Chain Rule）**的帮助，因此反向传播算法可以说是梯度下降在链式法则中的应用；

而链式法则是一个**连乘的形式**，所以当层数越深的时候，**梯度将以指数形式传播**；梯度消失问题和梯度爆炸问题一般随着网络层数的增加会变得越来越明显；在根据损失函数计算的误差通过梯度反向传播的方式对深度网络权值进行更新时，得到的**梯度值接近0**或**特别大**，也就是**梯度消失**或**爆炸**；

```
0 梯度消失：
 - 深层网络，雅各比矩阵最大特征值小于1  
 - 激活函数（Sigmoid）

1 梯度爆炸：
 - 深层网络，雅各比矩阵最大特征值大于1  
 - Weights初始化值太大
```



**解决方案：**

```
- 深层网络：
	- 残差结构(乘法改成加法，固定梯度1)

- 激活函数、权重：
	- 合理的激活函数：ReLU
	- 合理的参数初始化(He,Xavier,让每层均值和方差保持一致)
	- 权重衰减

- 梯度：
	- 梯度归一化/梯度剪切 -> 让梯度值在合理范围内[1e-6, 1e3]
	- Batch Normalization

- 预训练 + 微调
```



------



#### 权重初始化



一种比较简单有效的方法：$\quad(\mathrm{W}, \mathrm{b})$ 初始化从区间 $\left(-\frac{1}{\sqrt{d}}, \frac{1}{\sqrt{d}}\right)$均匀随机取值，**其中 $d$ 为 $（ \mathrm{~W}, \mathrm{~b}$ ） 所在层的神经元个数；**
可以证明：如果X服从正态分布, 均值0, 方差1，且各个维度无关, 而 $(\mathrm{W}, \mathrm{b})$ 是 $\left(-\frac{1}{\sqrt{d}}, \frac{1}{\sqrt{d}}\right)$ 的均匀分布, 则 $W^{T} X+b$ 是均值为0, 方差为1/3的正态分布；



**Kaiming初始化：**

- **前向传播**的时候, 每一层的**卷积计算的方差为1**；
- **反向传播**的时候, 每一层的继续往**前传的梯度方差为1**(因为每层会有两个梯度的计算, 一个用来更新当前层的权重, 一个继续传播,用于前面层的梯度的计算)；
- `torch.nn.init.kaiming_normal_(layer.weight,mode='fan_out', nonlinearity='relu')`



------



#### NAN & INF



**INF：**数值太大、权重初始值太大 、LearningRate太大；

**NAN：**Not a Number，计算异常如：除数为0产生、log(0)、sqrt(-x)等；

 

**INF解决方案：**

- 损失出现INF，反向传播参数更新为NAN，可选用适合的激活函数，对NAN、INF进行Mask；
- 权重初始化时保证其具有较小的方差；
- 使用较小LearningRate，或使用学习率衰减；
- 梯度剪裁、正则化：防止梯度爆炸（梯度消失）；
- 训练数据中出现脏数据：输入数据或者标签里面存在NaN；



------



#### 数据集划分



**验证集要和训练集来自于同一个分布（shuffle数据集然后开始划分），测试集尽可能贴近真实数据**



- 通常80%为训练集，20%为测试集
- 当**数据量较小**时（万级别）的时候将训练集、验证集以及测试集划分为**6：2：2**；若是**数据量很大**，可以将训练集、验证集、测试集比例调整为**98：1：1**
- 当数据量很小时，可以采用**K折交叉验证**
- 刚开始的时候，用训练集训练，验证集验证，确定超参数和一些细节；在验证集调到最优后，再把验证集丢进来训练，在测试集上测试
- 划分数据集时可采用随机划分法（当样本比较均衡时），分层采样法（当样本分布极度不均衡时）



------



#### L1&L2正则化



**正则化**之所以能够**降低过拟合**的原因在于：**正则化是结构风险最小化的一种策略实现**；



- **权重衰减**通过控制**L2正则**项使得模型参数不会过大，从而控制**模型复杂度**；
- **正则项权重**是控制模型复杂的**超参数**；
- 给Loss Function加上正则化项，能使得新得到的优化目标函数**h = f(w, b)+normal(w)**，需要在f和normal中做一个权衡，如果还像原来只优化f的情况下，那可能得到一组解比较复杂，使得正则项normal比较大，那么h就不是最优的，normal引入使得最优解向原点移动，因此可以看出**加正则项能实现参数的稀疏，让解更加简单，通过降低模型复杂度防止过拟合，提升模型的泛化能力**；

 

|          |                                               |       特点1        |         特点2          |                                                 |    作用    |                                                              |
| :------: | :-------------------------------------------: | :----------------: | :--------------------: | :---------------------------------------------: | :--------: | :----------------------------------------------------------: |
| L1正则化 |   在loss function后边所加**正则项为L1范数**   | 容易得到**稀疏解** | 容易产生**稀疏的权重** | 趋向于产生**少量的特征**，而**其他的特征都是0** |  特征选择  | **对异常值更鲁棒**；在0点不可导，计算不方便；**没有唯一解**；输出稀疏，会将不重要的特征直接置0； |
| L2正则化 | loss function后边所加**正则项为L2范数的平方** | 容易得到**平滑解** | 容易产生**分散的权重** |  会选择**更多的特征**，这些**特征都会接近于0**  | 防止过拟合 |  计算方便；**对异常值敏感**；**有唯一解**；**抗干扰能力强**  |

L1 范数：向量中**各个元素绝对值的和；**

L2 范数：向量中**各元素平方和**再**求平方根；**



------



#### 卷积Conv & 互相关 & 参数量计算



**卷积：**透过两个函数$f$和$g$生成第三个函数的一种数学算子，表征函数$f$与**经过翻转和平移的**$g$的乘积函数**所围成曲边梯形的面积**；

**互相关：**是两个函数之间的**滑动点积**，互相关中的过滤不经过反转，而是直接滑过函数$f$，$f$与$g$之间的**交叉区域**即是互相关；

**严格意义上来说，深度学习中的“卷积”是互相关运算，本质上执行逐元素乘法和加法**。但在之所以习惯性上将其称为卷积，是因为过滤器的权值是在训练过程中学习得到的；



**深度学习卷积**

```
1.局部连接； 2.权值共享； 3.层次结构；
```

- **每个通道之间不共享参数**，希望每个通道学到不同的模式；
- **不具有旋转不变性**：如果不是中心对称的像素团，旋转之后的卷积值肯定不一样；
- **不具有平移不变性**：同一个像素团，只要卷积核对齐了，卷积值都是一样的，但是**加了Padding的卷积网络平移不变性也是不存在的**，不带padding的网络每一层都必须进行严密的设计，如不带padding的UNet，通常为了网络设计简单，对训练样本做Padding是很有必要的；
- 如果**卷积的降采样过程丢弃边缘的像素，特征图像素与输入图像位置映射会产生偏移**，目前所有的深度学习框架都没有考虑这里的映射错位关系；

- **3x3卷积**
    - 底层专门做过优化，适合提取图像特征，已经成为主流组件；

- **1x1卷积**
    - 升维降维；
    - 减少参数；
    - 通道融合；
    - 增加非线性（利用后接的非线性激活函数）；

- **空洞卷积**
    - kernal之间增加空洞，增大感受野，图森组针对空洞卷组专门做过研究：[1, 3, 5, 1, 3, 5]这样的空洞率；
    - 虽然增大了感受野，但是使得特征更加稀疏；
    - **解决了网格效应**；
    - 在计算特征图时，k要替换为k + (r - 1) (k - 1)；

- **转置卷积**

    - **会出现棋盘效应：**由于转置卷积的“不均匀重叠”  -> **1.采取可以被步长整除的卷积核长度；  2.插值；**

    - 对于同一个卷积核，转置操作之后并不能恢复到原始的数值，而仅仅保留原始的形状，**因此上采样常用双线性插值；**


- **深度可分离卷积**
    - **MobileNet v1中提出：深度可分离卷积 = 深度卷积 + 1x1卷积；**



**参数量：**卷积核的尺寸是Dk×Dk×M，一共有N个

```
标准卷积参数量：Dk x Dk x M x N
深度卷积的卷积核尺寸Dk×Dk×M；逐点卷积的卷积核尺寸为1×1×M，一共有N个，所以深度可分离卷积的参数量是：Dk x Dk x M + M x N
```

**计算量**：普通卷积核的尺寸是Dk×Dk×M，一共有N个，每一个都要进行Dw×Dh次运算

```
标准卷积计算量：Dk x Dk x M x N x Dw x Dh
深度卷积的卷积核尺寸Dk×Dk×M，一共要做Dw×Dh次乘加运算；逐点卷积的卷积核尺寸为1×1×M，有N个，一共要做Dw×Dh次乘加运算，所以深度可分离卷积的计算量是：Dk x Dk x M x Dw x Dh +  M x N x Dw x Dh
```

**参数量和运算量均下降为原来的：**$\frac{1}{N}+\frac{1}{D_k^2}$



------



#### Padding 像素填充



- **保持边界信息**：如果没有加padding的话，输入图片最边缘的像素点信息只会被卷积核操作一次，但是图像中间的像素点会被扫描到很多遍，那么就会在一定程度上降低边界信息的参考程度，但是在加入padding之后，在实际处理过程中就会从新的边界进行操作，就从一定程度上解决了这个问题；
- 可以利用padding对输入尺寸有差异图片进行补齐，**使得输入图片尺寸一致**；
- 在卷积神经网络的卷积层加入Padding，可以使得**卷积层的输入维度和输出维度一致**；



------



#### Pooling 池化



- **Pooling层是模仿人的视觉系统对数据进行降维；**
- **池化类型：**最大/平均池化、全局池化、随机池化、ROI Pooling；
- **池化作用：**1. 抑制噪声，降低信息冗余；2. 提升模型的鲁棒性，防止过拟合；3. 降低模型计算量；
- **池化缺点：**造成梯度稀疏、丢失信息；



```
最大池化：保留主要特征，突出前景；
平均池化：保留背景信息，突出背景；
```



**Mean Pooling**

-  forward的时候，就是在前面卷积完的输出上依次不重合的取2x2的窗平均，得到一个值就是当前mean pooling之后的值；
- **backward的时候，把一个值分成四等分放到前面2x2的格子里面就好了；**（假设pooling的窗大小是2x2）
- 平均池化取每个块的平均值，提取特征图中所有特征的信息进入下一层；因此**当特征中所有信息都比较有用时，使用平均池化：**如网络最后几层，最常见的是进入分类部分的全连接层前，常常都使用平均池化，这是因为最后几层都包含了比较丰富的语义信息，使用最大池化会丢失很多重要信息；

```
forward: [1 3; 2 2] -> [2]
backward: [2] -> [0.5 0.5; 0.5 0.5]
```



**Max Pooling**

- forward的时候你只需要把2x2窗子里面那个最大的拿走就好了；
- **backward的时候你要把当前的值放到之前那个最大的位置，其他的三个位置都弄成0；**
- 最大池化的操作，取每个块中的最大值，而其他元素将不会进入下一层；CNN卷积核可以理解为在提取特征，对于最大池化取最大值，可以理解为提取特征图中响应最强烈的部分进入下一层，而其他特征进入待定状态；
- 一般而言，前景的亮度会高于背景，因此，最大池化具有提取主要特征、突出前景的作用；但在个别场合，前景暗于背景时，最大池化就不具备突出前景的作用了；
- **当特征中只有部分信息比较有用时，使用最大池化：如网络前面的层；图像存在噪声和很多无用的背景信息；**

```
forward: [1 3; 2 2] -> [3]
backward: [3] -> [0 3; 0 0]
```



------



#### 过采样 & 欠采样

原始数据大小为$\mathfrak{R}^{1831 \times 21}$，1831条数据，每条数据有21个特征：其中正例176个（9.6122%），反例1655个（90.3878%），类别不平衡;



**欠采样：**从反例中随机选择176个数据，与正例合并$\mathfrak{R}^{352 \times 21}$）

**过采样：**从正例中反复抽取并生成1655个数据（一定会重复），并与反例合并（ $\mathfrak{R}^{3310 \times 21}$ ）



- 使用采样方法一般可以**提升模型的泛化能力**，但有一定的**过拟合的风险**，应搭配使用正则化模型；
- **过采样的结果较为稳定**，过采样大部分时候比欠采样的效果好；
- **过采样**带来**更大的运算开销**，当数据中噪音过大时，结果反而可能会更差因为**噪音也被重复使用**；
- 尝试**半监督学习**的方法；注意积累样本；数据增强；可以训练多个模型，最后进行Model Ensemble；



------



#### 过拟合 & 欠拟合



**过拟合**指的是在训练集error越来越低，但是在验证集和测试集error不变或越来越高，模型拟合了训练样本中的噪声，导致泛化能力差；

```
数据增强
缩减模型表达能力
正则化（Weight Decay， L1，L2）
Early Stopping
Dropout / BN
```

**欠拟合**指的是训练集提取特征较少，导致模型不能很好拟合训练集；

```
增加模型复杂度  eg.ResNet-50 -> resNet-101；
减少正则化
错误分析：（训练集和测试集的分布偏差）测试时候出现问题进行分析，训练集缺少哪些情况导致错误，后续将在训练集中加入此类数据纠正偏差；
加入更多特征
```



------



## ########################################



## 目标检测



------

#### Label Assignment

- RetinaNet根据**Anchor和目标的IoU**来确定正负样本；
- FCOS根据**目标中心区域和目标的尺度**确定正负样本；



Assign算法的原则：

- 中心先验：FCOS / CenterNet
- Loss aware（动态匹配）：FreeAnchor / ATSS
- 不同目标设定不同数量正样本（进一步动态）：PAA / AutoAssign
- 全局信息：IQDet / OTA



------

#### ROI Pooling & Align

 

**两次整数化（量化）过程**：

- **region proposal**的xywh通常是小数，但是为了方便操作会把它整数化；
- 将整数化后的边界区域**平均分割成 k x k 个单元**，对每一个单元边界进行整数化；

**经过上述两次整数化，此时的候选框已经和最开始回归出来的位置有一定的偏差，这个偏差会影响检测或者分割的准确度；**  - >  **mis-alignment**



**ROI Align**: **取消量化操作**：

- 遍历每一个候选区域，保持浮点数边界不做量化，使用双线性内插的方法获得坐标为浮点数的像素点上的图像数值,从而**将整个特征聚集过程转化为一个连续的操作**；
- 将候选区域分割成k x k个单元，每个单元的边界也不做量化，在每个单元中计算固定四个坐标位置，用双线性内插的方法计算出这四个位置的值，然后进行最大池化操作；



------

#### Anchor-Base VS Anchor-Free



**Anchor-Based：**

- 检测性能**对于anchor的大小，数量，长宽比都非常敏感**，这些固定的anchor极大地**损害了检测器的泛化性**，导致对于不同任务，其anchor都必须重新设置大小和长宽比；
- 为了去匹配真实框，需要生成大量的anchor，但是大部分的anchor在训练时标记为negative，所以就造成**正负样本的不平衡**；
- 在训练中，需要**计算所有anchor与真实框的IOU**，这样就会**消耗大量内存和时间**；



**Anchor-Free：**

- **语义模糊性**，即两个物体的中心点落在了同一个网格中 ：
    - FCOS默认将该点分配给面积最小的目标；
    - 使用FPN界定每个特征层的检测范围；
    - center sampling准则；【只有GT bbox中心附近的一定范围内的小bbox内的点，分类时才作为正样本】
- anchor free缺少先验知识，所以优化不如anchor based的方法**稳定**；



------

#### 网络的分类



- [x] **基于Stage：**

    - **多阶：**Casade RCNN

     - **两阶：**RCNN / Fast RCNN / Faster RCNN

     - **单阶：**SSD / YOLO v1~v5 / RetinaNet / EfficientNet / CornerNet / FCOS

- [x] **是否使用Anchor：**

    - **Anchor Free:**
        - **Dense Prediction：**DenseBox
        - **Keypoint-based：**CenterNet / CornerNet

      - **Anchor based：**
        - **Dimension Clusters：**YOLO v2 ~ YOLO v5 / PP-YOLO / EfficientNet 

        - **Hand pickeed：**SSD / Faster RCNN


- [x] **不同标签方案：**
    - **Region proposal-based：**RCNN / Fast RCNN / Faster RCNN
    - **基于keypoint-based：**CornerNet / CenterNet / RepPoints

    - **基于author-IoU：**SSD / Faster RCNN / YOLO v2 ~ v5 / EfficientNet 



------

#### 传统目标检测



**区域选择->特征提取->分类器**

- 使用不同尺度的滑动窗口选定图像的某一区域为候选区域；
- 从对应的候选区域提取如Harrs HOG等一类或者多类**特征**；
- 使用 SVM 等分类算法对对应的候选区域进行分类，判断是否属于待检测的目标；



**缺点：**

- 基于滑动窗口的区域选择策略没有针对性，**时间复杂度高，窗口冗余；**
- 手工设计的特征对于多样性的变化没有很好的**鲁棒性**；

 

------





## ########################################

## 经典架构



#### ResNet & DenseNet







------



## ########################################

## 重要代码



#### Focal_Loss

- **alpha:** (optional) Weighting factor in range (0,1) to balance **positive vs negative examples** or -1 for ignore. Default = 0.25；
- **gamma:** Exponent of the modulating factor (1 - p_t) to balance **easy vs hard examples；**

```python
import torch
import torch.nn.functional as F

from ..utils import _log_api_usage_once



[docs]def sigmoid_focal_loss(
    inputs: torch.Tensor,
    targets: torch.Tensor,
    alpha: float = 0.25,
    gamma: float = 2,
    reduction: str = "none",
):
    """
    Args:
        inputs: A float tensor of arbitrary shape.
                The predictions for each example.
        targets: A float tensor with the same shape as inputs. Stores the binary
                classification label for each element in inputs
                (0 for the negative class and 1 for the positive class).
        alpha: (optional) Weighting factor in range (0,1) to balance
                positive vs negative examples or -1 for ignore. Default = 0.25
        gamma: Exponent of the modulating factor (1 - p_t) to
               balance easy vs hard examples.
        reduction: 'none' | 'mean' | 'sum'
                 'none': No reduction will be applied to the output.
                 'mean': The output will be averaged.
                 'sum': The output will be summed.
    Returns:
        Loss tensor with the reduction option applied.
    """
    if not torch.jit.is_scripting() and not torch.jit.is_tracing():
        _log_api_usage_once(sigmoid_focal_loss)
        
    p = torch.sigmoid(inputs)
    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction="none")
    p_t = p * targets + (1 - p) * (1 - targets)
    loss = ce_loss * ((1 - p_t) ** gamma)

    if alpha >= 0:
        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)
        loss = alpha_t * loss

    if reduction == "mean":
        loss = loss.mean()
    elif reduction == "sum":
        loss = loss.sum()

    return loss
```



------





## ########################################
